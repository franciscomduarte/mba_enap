import streamlit as st
import PyPDF2
import os
from openai import OpenAI
from dotenv import load_dotenv  # Para carregar variÃ¡veis do .env

# Carregar variÃ¡veis do .env
load_dotenv()

# Obter a chave da API do ambiente
api_key = os.getenv("OPENAI_API_KEY")

# Verificar se a API Key estÃ¡ definida
if not api_key:
    st.error("âš ï¸ A chave da API OpenAI nÃ£o foi encontrada. Verifique o arquivo .env.")
    st.stop()

client = OpenAI(api_key=api_key)

# DiretÃ³rio onde os PDFs estÃ£o armazenados
PDF_FOLDER = "pdfs/"

# FunÃ§Ã£o para extrair texto do PDF
def extrair_texto_pdf(pdf_path):
    texto = ""
    with open(pdf_path, "rb") as arquivo:
        leitor = PyPDF2.PdfReader(arquivo)
        for pagina in range(len(leitor.pages)):
            texto += leitor.pages[pagina].extract_text() + "\n"
    return texto

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(page_title="RAG com IA e PDFs", page_icon="ğŸ“„", layout="wide")

# Inicializar sessÃ£o para manter histÃ³rico e pergunta
if "historico" not in st.session_state:
    st.session_state.historico = []
if "pergunta" not in st.session_state:
    st.session_state.pergunta = ""

# Interface estilizada
st.markdown('<h1 class="main-title">ğŸ“„ğŸ” RAG com IA e PDFs</h1>', unsafe_allow_html=True)
st.markdown('<p class="sub-title">Pesquise conteÃºdos em documentos PDF com ajuda da IA!</p>', unsafe_allow_html=True)

# Carregar PDFs da pasta
pdf_files = [f for f in os.listdir(PDF_FOLDER) if f.endswith(".pdf")]

if not pdf_files:
    st.error("âš ï¸ Nenhum PDF encontrado na pasta 'pdfs/'. Adicione arquivos e reinicie o app.")
else:
    col1, col2 = st.columns([2, 3])

    with col1:
        selected_pdf = st.selectbox("ğŸ“‚ Escolha um PDF para pesquisa:", pdf_files)

    if selected_pdf:
        pdf_path = os.path.join(PDF_FOLDER, selected_pdf)

        with col2:
            pergunta = st.text_input("â“ Digite sua pergunta:", value=st.session_state.pergunta, key="input_pergunta")

        if st.button("ğŸ” Pesquisar", key="pesquisar"):
            if pergunta:
                with st.spinner("Aguarde... Buscando resposta..."):
                    texto_pdf = extrair_texto_pdf(pdf_path)
                    contexto = "\n".join([f"Pergunta: {h['pergunta']}\nResposta: {h['resposta']}" for h in st.session_state.historico])

                    prompt = f"Baseado no seguinte documento:\n\n{texto_pdf}\n\nHistÃ³rico da conversa:\n{contexto}\n\nPergunta: {pergunta}\nResposta:"
                    
                    try:
                        completion = client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[{"role": "user", "content": prompt}],
                            max_tokens=200
                        )
                        resposta = completion.choices[0].message.content

                        # Adicionar ao histÃ³rico
                        st.session_state.historico.append({"pergunta": pergunta, "resposta": resposta})

                        st.success("âœ… Resposta gerada com sucesso!")
                        st.markdown(f'<div class="historico-box"><strong>â“ Pergunta:</strong> {pergunta}<br><strong>ğŸ’¡ Resposta:</strong> {resposta}</div>', unsafe_allow_html=True)

                        # ğŸ”¥ Limpar o campo de pergunta
                        st.session_state.pergunta = ""
                        st.rerun()

                    except Exception as e:
                        st.error(f"Erro ao consultar IA: {e}")
            else:
                st.warning("âš ï¸ Digite uma pergunta antes de pesquisar.")

        # Exibir histÃ³rico de perguntas e respostas
        if st.session_state.historico:
            st.subheader("ğŸ“œ HistÃ³rico de Perguntas")
            for h in reversed(st.session_state.historico):
                st.markdown(f'<div class="historico-box"><strong>â“ {h["pergunta"]}</strong><br>ğŸ’¡ {h["resposta"]}</div>', unsafe_allow_html=True)